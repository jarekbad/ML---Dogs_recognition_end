{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dogs_recognition_end.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/zero-to-mastery-ml/blob/master/section-4-unstructured-data-projects/end-to-end-dog-vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "NtALLU9lQlDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "bpt0Mnc8DsS6"
      },
      "outputs": [],
      "source": [
        "# 0 Getting workspace ready.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# print(\"All imports are correct. Workspace is ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Defining a function.\n",
        "\n",
        "def process_image(image_path):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns it into a Tensor.\n",
        "  \"\"\"\n",
        "  IMG_SIZE = 224\n",
        "  # Read in image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # Resize the image to our desired size (224, 244)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "  return image\n",
        "\n",
        "\n",
        "def create_data_batches(image_paths):\n",
        "  \"\"\"\n",
        "  Creates batches (size=32) of data.\n",
        "  \"\"\"\n",
        "  print(\"Creating data batches...\")\n",
        "  data = tf.data.Dataset.from_tensor_slices((tf.constant(image_paths))) \n",
        "  data_batch = data.map(process_image).batch(32)  \n",
        "  return data_batch\n",
        "\n",
        "# def create_data_batches(x, y=None, BATCH_SIZE=32, valid_data=False, test_data=False):\n",
        "#   \"\"\"\n",
        "#   Creates batches of data out of image (x) and label (y) pairs.\n",
        "#   Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
        "#   Also accepts test data as input (no labels).\n",
        "#   \"\"\"\n",
        "#   # If the data is a test dataset, we probably don't have labels\n",
        "#   if test_data:\n",
        "#     print(\"Creating test data batches...\")\n",
        "#     data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
        "#     data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "#     return data_batch\n",
        "  \n",
        "#   # If the data if a valid dataset, we don't need to shuffle it\n",
        "#   elif valid_data:\n",
        "#     print(\"Creating validation data batches...\")\n",
        "#     data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "#                                                tf.constant(y))) # labels\n",
        "#     data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "#     return data_batch\n",
        "\n",
        "#   else:\n",
        "#     # If the data is a training dataset, we shuffle it\n",
        "#     print(\"Creating training data batches...\")\n",
        "#     # Turn filepaths and labels into Tensors\n",
        "#     data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "#                                               tf.constant(y))) # labels\n",
        "    \n",
        "#     # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "#     data = data.shuffle(buffer_size=len(x))\n",
        "\n",
        "#     # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
        "#     data = data.map(get_image_label)\n",
        "\n",
        "#     # Turn the data into batches\n",
        "#     data_batch = data.batch(BATCH_SIZE)\n",
        "#   return data_batch"
      ],
      "metadata": {
        "id": "NMxm7AP8D5bV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dogs_recognition():\n",
        "  # 1. Load the Model.\n",
        "  model_path = '/content/drive/MyDrive/Dogs_recognition/Dogs_recognition_Model.h5'\n",
        "  print(\"Model is loading...\")\n",
        "  model_dogs_recognition = tf.keras.models.load_model(model_path,  custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  print(\"Correct model load - Dogs_recognition_Model.\")\n",
        "  # 2. Prepare image and turn into batches - by using functions.\n",
        "  path = \"/content/drive/MyDrive/Dogs_recognition/Dogs/\"\n",
        "  image_paths = [path + fname for fname in os.listdir(path)]\n",
        "  new_data = create_data_batches(image_paths)  \n",
        "  # 3. Making predictions and prepare visualization\n",
        "  predictions = model_dogs_recognition.predict(new_data)\n",
        "  print(\"Making predictions...\")\n",
        "  # 4. Prepare labels for predictions\n",
        "  labels_csv = pd.read_csv(\"drive/MyDrive/Dogs_recognition/labels.csv\")\n",
        "  labels = labels_csv[\"breed\"].to_numpy() \n",
        "  unique_dogs_breeds = np.unique(labels)\n",
        "  predictions_labels = [unique_dogs_breeds[np.argmax(predictions[i])] for i in range(len(predictions))]\n",
        "  # 5. Prepare image (unbatch)\n",
        "  new_image = []\n",
        "  for image in new_data.unbatch().as_numpy_iterator():\n",
        "    new_image.append(image)\n",
        "  # 6. Check image predictions and visualization\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  for i, image in enumerate(new_image):\n",
        "    plt.subplot(1,len(predictions_labels), i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(predictions_labels[i])\n",
        "    plt.imshow(image)"
      ],
      "metadata": {
        "id": "GrHKeKfpKbO0"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dogs_recognition()"
      ],
      "metadata": {
        "id": "A9xZ51LKM7H9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}